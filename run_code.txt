# Single Card toy dataset

CUDA_VISIBLE_DEVICES=0 python -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --lr=1e-3 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --model PANN-14 \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" \
    --datasetinfos "train" "unbalanced_train" "balanced_train"


torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --lr=1e-3 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --freeze-text \
    --use-bn-sync  \
    --model PANN-14 \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" \
    --datasetinfos "train" "unbalanced_train" "balanced_train"




# run with wandb
torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --split-opt \
    --lr=1e-3 \
    --lr-new=1e-4 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --model PANN-14 \
    --report-to "wandb" \
    --wandb-notes "text-audio-diff-lr-1e-3-1e-4-model-pann-14" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" \
    --datasetinfos "train" "unbalanced_train" "balanced_train" \

torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --split-opt \
    --lr=1e-3 \
    --lr-new=1e-4 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --model PANN-14 \
    --report-to "wandb" \
    --wandb-notes "text-audio-diff-lr-1e-3-1e-4-model-pann-14" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" \
    --datasetinfos "train" "unbalanced_train" "balanced_train" "eval" \

torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --split-opt \
    --lr=1e-3 \
    --lr-new=1e-4 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --model HTSAT-tiny \
    --report-to "wandb" \
    --wandb-notes "text-audio-diff-lr-1e-3-1e-4-model-htsat-tiny" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" \
    --datasetinfos "train" "unbalanced_train" "balanced_train" "eval" \


# tomorrow for yusong

torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --lr=1e-3 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --freeze-text \
    --model PANN-14 \
    --report-to "wandb" \
    --wandb-notes "text-audio-freeze-text-lr-1e-3-model-pann-14" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" "audioset"  \
    --datasetinfos "train" "unbalanced_train" "balanced_train" "eval" \

torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --lr=1e-3 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --freeze-text \
    --model HTSAT-tiny \
    --report-to "wandb" \
    --wandb-notes "text-audio-freeze-text-lr-1e-3-model-htsat-tiny" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects" "audioset"  \
    --datasetinfos "train" "unbalanced_train" "balanced_train" "eval" \

# freeze text after epoch 3 and make lr-pretrained=1e-5
torchrun --nproc_per_node 8 -m training.main \
    --save-frequency 100 \
    --save-top-performance 3  \
    --save-most-recent \
    --dataset-type="webdataset" \
    --precision="fp32" \
    --pretrained="openai" \
    --warmup 10000  \
    --batch-size=96 \
    --lr-new=1e-3 \
    --lr-pretrained=1e-5 \
    --freeze-text-after=5 \
    --wd=0.1 \
    --epochs=200  \
    --workers=4 \
    --use-bn-sync  \
    --model PANN-14 \
    --report-to "wandb" \
    --wandb-notes "text-audio-diff-lr-1e-3-1e-5-freeze-after-5-model-pann-14" \
    --resample-method="None" \
    --datasetnames "Clotho" "audiocaps" "BBCSoundEffects"  \
    --datasetinfos "train" "unbalanced_train" "balanced_train" "eval" \
